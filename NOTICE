SparseZoo
Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved.

This product includes software developed at Neuralmagic, Inc. (https://www.neuralmagic.com).

Source code in this repository is variously licensed under the Apache License
Version 2.0, an Apache-compatible license.

* For a copy of the Apache License Version 2.0, please see [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0).

* For a copy of the Neural Magic DeepSparse Community License, please see LICENSE
 as included in the Neural Magic's "deepsparse" repository.

* For a copy of all other Apache-compatible licenses and notices,
  they will be listed below.

========================================================================
NOTICES
========================================================================

All implementations in this repository are subject to Neural Magic's Legal Policies https://www.neuralmagic.com/legal

Transformers code implementations https://github.com/huggingface/transformers/blob/main/LICENSE

Models that are derivatives of other model frameworks are indicated as such below (along with their GitHub repository names appended) and are used in accordance with their original licenses and terms:

* BERT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* BioBERT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* CodeGen Mono https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* CodeGen Multi https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* DistilBERT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* EfficientNet https://github.com/tensorflow/tpu/blob/master/LICENSE (sparseml)
* EfficientNetv2 https://github.com/tensorflow/tpu/blob/master/LICENSE (sparseml)
* Inceptionv3 https://github.com/pytorch/vision/blob/main/LICENSE  (sparseml)
* Llama 2  https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* Mistral  https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* mnistnet https://github.com/mtn/mnistnet/blob/master/LICENSE (sparseml)
* MobileBERT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* MobileNetv1 https://github.com/osmr/imgclsmob/blob/956b4ebab0bbf98de4e1548287df5197a3c7154e/LICENSE (sparseml)
* MobileNetv2 https://github.com/keras-team/keras/blob/v2.14.0/LICENSE (sparseml)
* MPT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* oBERT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* oBERTa https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* OPT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* ResNetv1 https://github.com/KaimingHe/deep-residual-networks/blob/master/LICENSE (sparseml)
* Roberta https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* SecureBERT https://github.com/huggingface/transformers/blob/main/LICENSE (huggingface)
* SSD https://github.com/weiliu89/caffe/blob/master/LICENSE (sparseml)
* VGG https://creativecommons.org/licenses/by/4.0/ (sparseml)
* YOLACT https://github.com/dbolya/yolact/blob/master/LICENSE (dbolya) 
* YOLOv3, YOLOv5, YOLOv8  https://github.com/neuralmagic/sparseml/blob/master/LICENSE-ULTRALYTICS (ultralytics)

Package dependencies are defined in the Python setup.py file in this repository's top-level directory and have their own Apache-compatible licenses and terms.

Other external dependencies, if referenced in this repository's various subdirectories, are subject to their associated licenses and terms. 
