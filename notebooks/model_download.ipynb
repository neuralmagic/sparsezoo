{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© 2022 Neuralmagic, Inc. // [Neural Magic Legal](https://neuralmagic.com/legal)\n",
    "# Downloading from Sparsezoo\n",
    "\n",
    "This notebook provides an easy step-by-step walkthrough for downloading a model from the Sparsezoo model repository. You will:\n",
    "- Set up the environment\n",
    "- Select a model\n",
    "- Download the model\n",
    "\n",
    "Reading through this notebook will quickly provide an overview of the pretrained, performance-tuned models available in the Sparsezoo. This will take approximately:\n",
    "- 15 minutes\n",
    "\n",
    "# Background\n",
    "Neural networks can take a long time to train. Model sparsification techniques such as model pruning may be necessary to achieve both performance and sparsification goals. However, the sparsification of models can involve many trials and errors due to a large number of hyperparameters. Fortunately, in the computer vision and natural language space, pruned (sparsiﬁed) neural networks transfer learn.\n",
    "\n",
    "To make it easier to use pruned models, Neural Magic is actively:\n",
    "- Creating pruned versions of popular models and datasets\n",
    "- Thoroughly testing these models with the DeepSparse Engine to ensure performance\n",
    "- Updating the Sparsezoo Repo with these models and datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Setting Up the Environment\n",
    "\n",
    "In this step, Neural Magic checks your environment setup to ensure the rest of the notebook will flow smoothly.\n",
    "Before running, install the sparsezoo package into the system using the following at the parent of the package directory:\n",
    "\n",
    "`pip install sparsezoo/ `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "notebook_name = \"model_repo\"\n",
    "print(\"checking setup for {}...\".format(notebook_name))\n",
    "\n",
    "# filter because of tensorboard future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    # make sure sparsezoo is installed\n",
    "    import sparsezoo\n",
    "    print(\"sparsezoo available for model download\")\n",
    "except Exception as ex:\n",
    "    raise Exception(\n",
    "        \"please install sparsezoo using the setup.py file before continuing\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Selecting a Model\n",
    "\n",
    "SparseZoo repository holds a wide range of different models. We display all of the them on the main page of [SparseZoo](https://sparsezoo.neuralmagic.com/). \n",
    "\n",
    "Once a model of interest is found, the next step is to fetch the stub of the model. A stub is a short string, serving as a pointer to the model data stored. An example of a stub is `zoo:cv/classification/vgg-19/pytorch/sparseml/imagenet/pruned-moderate`. The stub can be used to download the model.\n",
    "\n",
    "Alternatively, one may use `search_models` function, to directly search for appropriate model from Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sparsezoo import Model, search_models, clean_path\n",
    "\n",
    "download_path = clean_path(os.path.join(\".\", notebook_name))\n",
    "\n",
    "## Selecting a model from a retrieved stub ##\n",
    "\n",
    "stub = \"zoo:cv/classification/vgg-19/pytorch/sparseml/imagenet/pruned-moderate\"\n",
    "model = Model(stub)\n",
    "print(f\"Retrieved a model\\n{str(model)}\\nfrom a stub:{stub}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting a model using the search functionality ##\n",
    "\n",
    "n_first_print = 5  # print out first n models found\n",
    "domain, sub_domain = \"cv\", \"classification\"  # defining the search criteria\n",
    "\n",
    "print(\"Searching for models...\")\n",
    "model_stubs = search_models(domain, sub_domain, return_stubs=True)\n",
    "print(f\"Given the search criteria, found {len(model_stubs)} models...\")\n",
    "print(f\"Printing first {n_first_print} model stubs...\")\n",
    "[print(f\"\\t{stub}\") for stub in model_stubs[:n_first_print]]\n",
    "model_stub = model_stubs[0]\n",
    "print(f\"\\nSelecting the first model: {str(model_stub)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Downloading the Model\n",
    "\n",
    "After making a model selection, run the cell block below to download the model locally from the selected stub. By default, it will save the model to an appropriately named folder under the current working directory. You can change the save_dir if you'd like to save to another location on the local system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model = Model(model_stub)\n",
    "# calling .path triggers model download\n",
    "print(f\"Model download to {model.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "You may want to explore one of these paths:\n",
    "- Optimize the model further with the SparseML package\n",
    "- Test the performance in an inference engine that supports sparsity such as the DeepSparse Engine\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
